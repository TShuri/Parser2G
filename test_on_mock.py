import json
import time
import re
import logging
import datetime
import os
import sys
import signal
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager


class AddressParser:
    def __init__(self, headless=False):
        self.headless = headless
        # –û–±—â–∏–µ —Å—á–µ—Ç—á–∏–∫–∏
        self.counter = {
            "build": 0,
            "orgs_in_build": 0,
            "parsed_build": 0,
            "parsed_orgs_in_build": 0,
            "saved_build_json": 0,
            "saved_orgs_in_build_json": 0,

            "error_address_processing": 0,
            "error_intercept_network": 0,
            "error_not_found_build_id": 0,
            "many_files_orgs_in_build": 0,

            "start_time": 0,
            "end_time": 0
        }
        self.driver = self.init_browser()

    def init_browser(self):
        """ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Selenium WebDriver —Å DevTools """
        options = webdriver.ChromeOptions()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        if self.headless:
            options.add_argument("--headless")

        options.set_capability("goog:loggingPrefs", {"performance": "ALL"}) # –í–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.maximize_window()

        self.counter["start_time"] = datetime.datetime.now().isoformat()

        return driver

    def wait_for_page_load(self, timeout=10):
        """–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        WebDriverWait(self.driver, timeout).until(
            lambda driver: driver.execute_script("return document.readyState") == "complete"
        )

    def clear_cache_and_cookies(self):
        """ –û—á–∏—Å—Ç–∫–∞ –∫–µ—à –∏ –∫—É–∫–∏ """
        try:
            self.driver.execute_cdp_cmd("Network.clearBrowserCache", {})
            self.driver.execute_cdp_cmd("Network.clearBrowserCookies", {})
            print("üßπ –ö—ç—à –∏ –∫—É–∫–∏ –æ—á–∏—â–µ–Ω—ã")

        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞ –∏ –ª–æ–≥–æ–≤: {e}")

    def intercept_network_requests(self, building_id, have_organizations):
        """ –ü–µ—Ä–µ—Ö–≤–∞—Ç –Ω—É–∂–Ω–æ–≥–æ byid-–∑–∞–ø—Ä–æ—Å–∞ """
        try:
            time.sleep(3)  # –í—Ä–µ–º—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
            logs = self.driver.get_log("performance")

            target_byid_request = None
            target_byid_request_id = None
            target_orgs_request = None
            target_orgs_request_id = None

            entry_byid = f"byid?id={building_id}"
            # entry_orgs_pattern = re.compile(r"list\?key.*building_id=" + str(building_id))
            entry_orgs = "list?key"

            count_entry_list = 0

            for log in logs:
                log_json = json.loads(log["message"])["message"]

                if log_json["method"] == "Network.responseReceived":
                    request_id = log_json["params"]["requestId"]
                    response_url = log_json["params"]["response"]["url"]

                    if entry_byid in response_url: # –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã–π "byid", —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ
                        target_byid_request = response_url
                        target_byid_request_id = request_id
                        self.counter["parsed_build"] += 1

                    if have_organizations and (entry_orgs in response_url): # –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã–π "list"
                        target_orgs_request = response_url
                        target_orgs_request_id = request_id
                        self.counter["parsed_orgs_in_build"] += 1
                        count_entry_list += 1 # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏

            if count_entry_list > 1: # –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏ –º–Ω–æ–≥–æ, —Ç–æ —ç—Ç–æ –ø–ª–æ—Ö–æ
                self.counter["many_files_orgs_in_build"] += 1

            # print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ –ø—Ä–∏ –æ–¥–Ω–æ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç–µ: {len(logs)}")
            # print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–∞ list?key –ø—Ä–∏ –æ–¥–Ω–æ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç–µ: {count_entry_list}")

            # –ü–æ–ª—É—á–µ–Ω–∏–µ JSON –∑–¥–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            if target_byid_request and target_byid_request_id:
                response = self.driver.execute_cdp_cmd("Network.getResponseBody", {"requestId": target_byid_request_id})
                data = json.loads(response["body"])

                folder_name = "builds_json"
                os.makedirs(folder_name, exist_ok=True)
                filename = os.path.join(folder_name, f"byid_{building_id}.json")
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)

                self.counter["saved_build_json"] += 1
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ –∑–¥–∞–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
                logging.info("The building data is saved in json")

            # –ü–æ–ª—É—á–µ–Ω–∏–µ JSON –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            if target_orgs_request and target_orgs_request_id:
                response = self.driver.execute_cdp_cmd("Network.getResponseBody",{"requestId": target_orgs_request_id})
                data = json.loads(response["body"])

                folder_name = "orgs_in_builds_json"
                os.makedirs(folder_name, exist_ok=True)
                filename = os.path.join(folder_name, f"list_{building_id}.json")
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)

                self.counter["saved_orgs_in_build_json"] += 1
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
                logging.info("Information about organizations is saved in json")

        except Exception as e:
            self.counter["error_intercept_network"] += 1
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç–µ –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            logging.error(f"Error when intercepting requests: {e}")

    @staticmethod
    def extract_building_id(href):
        """ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –∑–¥–∞–Ω–∏—è –∏–∑ —Å—Å—ã–ª–∫–∏ """
        match = re.search(r"/irkutsk/[^/]+/(\d+)", href)
        if match:
            return match.group(1)
        return None

    def process_address(self, address):
        """ –ü–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞ –≤ 2GIS """
        self.driver.get("https://2gis.ru/irkutsk")
        self.wait_for_page_load()

        try:
            # –≠–ª–µ–º–µ–Ω—Ç –ü–æ–ª–µ –ø–æ–∏—Å–∫–∞
            input_box = WebDriverWait(self.driver, 10).until(
                # EC.presence_of_element_located((By.CSS_SELECTOR, "input._h7eic2"))
                EC.presence_of_element_located((By.CSS_SELECTOR, "input._cu5ae4"))
            )
            input_box.clear()
            input_box.send_keys(address)

            # –≠–ª–µ–º–µ–Ω—Ç –ü–æ–¥—Å–∫–∞–∑–æ–∫ –ø–æ–∏—Å–∫–∞
            suggestion = WebDriverWait(self.driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "li._1914vup"))
            )
            suggestion.click()

            # –≠–ª–µ–º–µ–Ω—Ç –ò–Ω—Ñ–æ
            info_element = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//a[text()='–ò–Ω—Ñ–æ']"))
            )
            href = info_element.get_attribute("href")

            # –ù–∞–ª–∏—á–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ –∑–¥–∞–Ω–∏–∏
            have_organizations = False
            try:
                # –≠–ª–µ–º–µ–Ω—Ç –í –∑–¥–∞–Ω–∏–∏ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏)
                in_building = WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.XPATH, "//a[text()='–í –∑–¥–∞–Ω–∏–∏']"))
                )
                in_building.click()
                have_organizations = True
                print("‚úÖ –ï—Å—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ –¥–∞–Ω–Ω–æ–º –∑–¥–∞–Ω–∏–∏")
                logging.info("There are organizations in this building")

            except Exception as eOrganizationsNotFound:
                print("‚≠ï –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ –¥–∞–Ω–Ω–æ–º –∑–¥–∞–Ω–∏–∏ –Ω–µ—Ç")
                logging.info("There are no organizations in this building")

            building_id = self.extract_building_id(href)
            if building_id:
                self.counter["build"] += 1
                if have_organizations:
                    self.counter["orgs_in_build"] += 1

                print(f"‚úÖ –ù–∞–π–¥–µ–Ω building_id: {building_id}")
                logging.info(f"building_id found: {building_id}")

                self.intercept_network_requests(building_id, have_organizations)
            else:
                self.counter["error_not_found_build_id"] += 1
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ building_id –≤ —Å—Å—ã–ª–∫–µ!")
                logging.error("Couldn't find the building_id in the link!")

            #self.clear_cache_and_cookies()

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–¥—Ä–µ—Å–∞ {address}: {e}")
            logging.error(f"Address processing error {address}: {e}")

            return False

        return True

    def run(self):
        """ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ """
        try:
            addresses = [
                "—É–ª–∏—Ü–∞ –õ–µ—Ä–º–æ–Ω—Ç–æ–≤–∞, 83",
                "—É–ª–∏—Ü–∞ –õ–µ–Ω–∏–Ω–∞, 15",
                "1-–π –î–∞—á–Ω—ã–π –ø–µ—Ä–µ—É–ª–æ–∫, 7"
            ]

            for address in addresses:
                print(f"\nüîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {address}")
                logging.info(f"{'-' * 40} Processing: {address} {'-' * 40}")
                success = self.process_address(address)

                if not success:
                    print("‚≠ï –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞–¥—Ä–µ—Å, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥")
                    logging.error("The address could not be processed, a second attempt after 10 seconds")
                    time.sleep(10)
                    self.process_address(address)

                time.sleep(2)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

        finally:
            self.counter["end_time"] = datetime.datetime.now().isoformat()

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ñ–∞–π–ª
            with open("parser_stats.json", "w", encoding="utf-8") as f:
                json.dump(self.counter, f, ensure_ascii=False, indent=4)

            print(self.counter)
            logging.info("The final statistics are saved in parser_stats.json")

            self.driver.quit()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s", filename="parser.log",
                        filemode="w") # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

    parser = AddressParser(headless=False)

    def signal_handler(sig, frame): # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        print("\nüõë –ü–∞—Ä—Å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä...")

        if parser:
            parser.counter["end_time"] = datetime.datetime.now().isoformat()

            # üìå –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º
            with open("parser_stats.json", "w", encoding="utf-8") as f:
                json.dump(parser.counter, f, ensure_ascii=False, indent=4)

            print(parser.counter)  # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å
            logging.info("The final statistics are saved in parser_stats.json")

            # üìå –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            if parser.driver:
                parser.driver.quit()

        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)

    parser.run()




